{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent import *\n",
    "model = LatentLM(\"gpt2-medium\", model=gpt_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 2, 6] <-> 'How[TOK]'\n",
       "                                        'What are you up to[TOK]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = model([\"How\", \"What are you up to\"])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.layer(-1).LatentTensor[2, 6] <-> 'How[TOK]'\n",
       "                                              'What are you up to[TOK]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.layer(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 2, 6] <-> 'How[TOK]'\n",
       "                                        'What are you up to[TOK]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gpt2-medium.LatentTensor[25, 2, 7] <-> 'How did[TOK]'\n",
      "                                        'What are you up to?[TOK]'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r.complete())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 2, 7] <-> 'How did[TOK]'\n",
       "                                        'What are you up to?[TOK]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.6751,  -8.6013, -13.2165,  ..., -18.4128, -12.4559, -10.6140],\n",
       "        [ -5.5568, -10.8951, -11.8829,  ..., -19.0959, -19.4955,  -9.3850]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.layer(-1).LatentTensor[2, 6] <-> 'How[TOK]'\n",
       "                                              'What are you up to[TOK]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.layer(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 1, 12] <-> 'The boat is red. The color of the boat is[TOK]'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = \"red\"\n",
    "y = model(f\"The boat is {color}. The color of the boat is\", name='hard_color')\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"blue\"]\n",
    "soft_color = model([[\"The boat is \", colors, \".\"]], name='soft_color')[-2]\n",
    "soft_color = adapter(soft_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1024]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 2, 7] <-> '{Adapter(soft_color)}The color of the boat is[TOK]'\n",
       "                                        '{Adapter(soft_color)}The color of the boat is[TOK]'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model([[soft_color, \"The color of the boat is\"]], name='soft_color')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentEqualityObjective:\n",
       " - <gpt2-medium.layer(-1).LatentTensor[1, 1] <-> ' is[TOK]'\n",
       "\n",
       " - <gpt2-medium.layer(-1).LatentTensor[1, 1] <-> ' is[TOK]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from latent import *\n",
    "\n",
    "class Adapter(LatentModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(1024, 1024)\n",
    "        # self.lin2 = torch.nn.Linear(32, 4096)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        return x\n",
    "    \n",
    "adapter = Adapter().to(model.device)\n",
    "\n",
    "def color_match(colors: List[str]):\n",
    "    soft_color = model([[\"The boat is \", colors, \".\"]], name='soft_color')[-2]\n",
    "    soft_color = adapter(soft_color)\n",
    "    x = model([[soft_color, \"The color of the boat is\"]], name='soft_color')\n",
    "    \n",
    "    y = model([[\"The boat is \", colors, \". The color of the boat is\"]], name='hard_color')\n",
    "    \n",
    "    return x.layer(-1)[-1] == y.layer(-1)[-1]\n",
    "color_match([\"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                                                            | 0/10000 [18:03<?, ?it/s]\n",
      "Epoch:   0%|                                                                                                                            | 0/10000 [17:29<?, ?it/s]\n",
      "Epoch 1/100, loss=0.3156:   0%|                                                                                            | 3/10000 [16:40<925:41:42, 333.35s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 1, 13] <-> 'The boat is pink. The color of the boat is pink[TOK]'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = \"pink\"\n",
    "model([f\"The boat is {color}. The color of the boat is\"], name='hard_color').complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt2-medium.LatentTensor[25, 1, 15] <-> '{Adapter(soft_color)}The color of the boat is the[TOK]'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color = \"pink\"\n",
    "soft_color = model(f\"The boat is {color}.\", name='soft_color')[-1]\n",
    "soft_color = adapter(soft_color)\n",
    "x = model([[soft_color, \"The color of the boat is\"]], name='soft_color')\n",
    "x.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aqua', 'black', 'blue', 'brown', 'cardinal', 'champagne', 'charcoal', 'chocolate', 'cinnamon', 'coral', 'corn', 'cream', 'cyan', 'denim', 'ecru', 'emerald', 'eggplant', 'gold', 'goldenrod', 'green', 'grey', 'indigo', 'ivory', 'khaki', 'lime', 'mustard', 'olive', 'orange', 'peach', 'pear', 'pink', 'puce', 'pumpkin', 'purple', 'red', 'rose', 'salmon', 'silver', 'smalt', 'tomato', 'violet', 'white', 'yellow']\n"
     ]
    }
   ],
   "source": [
    "colors = []\n",
    "with open(\"working_colors.txt\") as f:\n",
    "    for color in f:\n",
    "        colors.append(color.strip())\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0/100:   0%|                                                                                                                        | 0/375 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=0.1251:   0%|                                                                                                           | 0/375 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=0.1251:   0%|▎                                                                                                  | 1/375 [00:03<22:33,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=0.4098:   0%|▎                                                                                                  | 1/375 [00:06<22:33,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=0.4098:   1%|▌                                                                                                  | 2/375 [00:06<19:44,  3.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=0.8521:   1%|▌                                                                                                  | 2/375 [00:09<19:44,  3.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=0.8521:   1%|▊                                                                                                  | 3/375 [00:09<19:27,  3.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=1.7388:   1%|▊                                                                                                  | 3/375 [00:11<19:27,  3.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 1/100, loss=1.7388:   1%|█                                                                                                  | 4/375 [00:11<17:34,  2.84s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7388 Train accuracy: 56.67% Test accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 2/100, loss=1.6750:   1%|█                                                                                                  | 4/375 [00:20<17:34,  2.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=1.6750:   1%|█▎                                                                                                 | 5/375 [00:20<29:06,  4.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=1.7953:   1%|█▎                                                                                                 | 5/375 [00:22<29:06,  4.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=1.7953:   2%|█▌                                                                                                 | 6/375 [00:22<25:05,  4.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=2.0655:   2%|█▌                                                                                                 | 6/375 [00:25<25:05,  4.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=2.0655:   2%|█▊                                                                                                 | 7/375 [00:25<22:58,  3.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=2.7532:   2%|█▊                                                                                                 | 7/375 [00:28<22:58,  3.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 2/100, loss=2.7532:   2%|██                                                                                                 | 8/375 [00:28<21:18,  3.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7532 Train accuracy: 56.67% Test accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 3/100, loss=2.5834:   2%|██                                                                                                 | 8/375 [00:37<21:18,  3.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=2.5834:   2%|██▍                                                                                                | 9/375 [00:37<30:39,  5.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=2.6034:   2%|██▍                                                                                                | 9/375 [00:40<30:39,  5.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=2.6034:   3%|██▌                                                                                               | 10/375 [00:40<27:02,  4.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=2.7650:   3%|██▌                                                                                               | 10/375 [00:43<27:02,  4.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=2.7650:   3%|██▊                                                                                               | 11/375 [00:43<24:19,  4.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=3.3088:   3%|██▊                                                                                               | 11/375 [00:45<24:19,  4.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 3/100, loss=3.3088:   3%|███▏                                                                                              | 12/375 [00:45<21:28,  3.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.3088 Train accuracy: 56.67% Test accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 4/100, loss=3.0728:   3%|███▏                                                                                              | 12/375 [00:54<21:28,  3.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.0728:   3%|███▍                                                                                              | 13/375 [00:54<30:36,  5.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.0329:   3%|███▍                                                                                              | 13/375 [00:57<30:36,  5.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.0329:   4%|███▋                                                                                              | 14/375 [00:57<26:31,  4.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.1321:   4%|███▋                                                                                              | 14/375 [01:00<26:31,  4.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.1321:   4%|███▉                                                                                              | 15/375 [01:00<23:44,  3.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.5896:   4%|███▉                                                                                              | 15/375 [01:03<23:44,  3.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 4/100, loss=3.5896:   4%|████▏                                                                                             | 16/375 [01:03<21:51,  3.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.5896 Train accuracy: 56.67% Test accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 5/100, loss=3.3207:   4%|████▏                                                                                             | 16/375 [01:12<21:51,  3.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.3207:   5%|████▍                                                                                             | 17/375 [01:12<31:35,  5.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.2508:   5%|████▍                                                                                             | 17/375 [01:15<31:35,  5.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.2508:   5%|████▋                                                                                             | 18/375 [01:15<27:22,  4.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.3178:   5%|████▋                                                                                             | 18/375 [01:18<27:22,  4.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.3178:   5%|████▉                                                                                             | 19/375 [01:18<24:46,  4.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.7284:   5%|████▉                                                                                             | 19/375 [01:21<24:46,  4.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 5/100, loss=3.7284:   5%|█████▏                                                                                            | 20/375 [01:21<21:46,  3.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.7284 Train accuracy: 56.67% Test accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 6/100, loss=3.4413:   5%|█████▏                                                                                            | 20/375 [01:30<21:46,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.4413:   6%|█████▍                                                                                            | 21/375 [01:30<31:23,  5.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.3534:   6%|█████▍                                                                                            | 21/375 [01:33<31:23,  5.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.3534:   6%|█████▋                                                                                            | 22/375 [01:33<27:34,  4.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.4031:   6%|█████▋                                                                                            | 22/375 [01:36<27:34,  4.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.4031:   6%|██████                                                                                            | 23/375 [01:36<25:27,  4.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.7791:   6%|██████                                                                                            | 23/375 [01:39<25:27,  4.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 6/100, loss=3.7791:   6%|██████▎                                                                                           | 24/375 [01:39<22:16,  3.81s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.7791 Train accuracy: 56.67% Test accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 7/100, loss=3.4856:   6%|██████▎                                                                                           | 24/375 [01:48<22:16,  3.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "Epoch 7/100, loss=3.4856:   7%|██████▌                                                                                           | 25/375 [01:48<31:14,  5.35s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train, test \u001b[38;5;241m=\u001b[39m colors[:\u001b[38;5;241m30\u001b[39m], colors[\u001b[38;5;241m30\u001b[39m:]\n\u001b[0;32m----> 2\u001b[0m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor_match\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrossentropy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/lat/latent.py:769\u001b[0m, in \u001b[0;36mLatentModule.fit\u001b[0;34m(self, objective_fct, samples, loss_fct, epochs, lr, test, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    768\u001b[0m loss \u001b[38;5;241m=\u001b[39m LatentModule\u001b[38;5;241m.\u001b[39mloss(objective_fct(batch), loss_fct\u001b[38;5;241m=\u001b[39mloss_fct)\n\u001b[0;32m--> 769\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    772\u001b[0m moving_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m \u001b[38;5;241m*\u001b[39m moving_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Developer/miniconda3/envs/lmql/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/miniconda3/envs/lmql/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train, test = colors[:30], colors[30:]\n",
    "adapter.fit(color_match, train, epochs=100, lr=1e-4, loss_fct=\"crossentropy\", test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
